{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Together\n",
    "\n",
    "DBSCAN is a non-parametric clustering algorithm, meaning it does not make any assumptions about the shape of the clusters. This is great news for clusters that look like this:\n",
    "\n",
    "<img src = \"https://drive.google.com/uc?export=view&id=1oEgxzeR3ryvs-jp3OHv1jty6EgOs1wlz\" alt=\"Q\" style=\"width: 500px;\"/>\n",
    "\n",
    "It also introduces the concept of \"Noise\": data points that don't really fit into *any* cluster, like the smattering of points in database 3.\n",
    "\n",
    "## Algo Review\n",
    "In general, the algorithm is iterative, starting with a random core point, and finding all the **density connected/reachable** points from that **core point** and putting them into a cluster. Then it moves on to the next point.\n",
    "\n",
    "<img src = \"https://drive.google.com/uc?export=view&id=1XhHBpFnzgX2gx3vGT7LLNLCVXKbgqqY5\" alt=\"Q\" style=\"width: 300px;\"/>\n",
    "\n",
    "If a data point is **noise**, it marks it as such and moves on. This process repeats until all data points have been categorized.\n",
    "\n",
    "\n",
    "<img src = \"https://drive.google.com/uc?export=view&id=10ciqJpBrcnH7-Qdg2qokOHAIPbyub0p0\" alt=\"Q\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIL in Python\n",
    "\n",
    "To get the PIL library in python, run `pip install pillow` in terminal/command prompt.\n",
    "\n",
    "If you have a MAC you may need to say `pip3 install pillow`.\n",
    "\n",
    "If you get an error about not having permission, you may need to run `sudo pip install pillow` or `sudo pip3 install pillow` (MAC) and then enter your password.\n",
    "\n",
    "If none of this works, feel free to use [Google Colab](https://colab.research.google.com/) for this classwork.\n",
    "\n",
    "## Loading in an image using the PIL package\n",
    "\n",
    "Download the [MountainLandscape](https://github.com/cmparlettpelleriti/CPSC392ParlettPelleriti/blob/master/Data/Images/MountainLandscape.jpg) and [chrome](https://github.com/cmparlettpelleriti/CPSC392ParlettPelleriti/blob/master/Data/Images/chrome.jpg) images from github and store them somewhere convenient on your computer, like your desktop, or CPSC 392 folder. For example, the file path for the mountains on my computer is `/Users/cparlett/Desktop/Desktop/School/CPSC392ParlettPelleriti/Data/Images/MountainLandscape.jpg`.\n",
    "\n",
    "Find YOUR filepath, and copy it as a string into the variable `mountainPath`. You'll need to do the same with the chrome image later in this classwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the image\n",
    "\n",
    "mountainPath = '' ### PUT YOUR PATH HERE\n",
    "\n",
    "mount = Image.open(mountainPath,'r')\n",
    "\n",
    "# grab the image size\n",
    "width, height = mount.size\n",
    "\n",
    "# turn the image into a data frame of all the pixels\n",
    "# with RBG columns\n",
    "pixels = list(mount.getdata())\n",
    "\n",
    "R = [i[0] for i in pixels]\n",
    "G = [i[1] for i in pixels]\n",
    "B = [i[2] for i in pixels]\n",
    "\n",
    "mount_df = pd.DataFrame({\"R\": R,\n",
    "                        \"G\": G,\n",
    "                        \"B\": B})\n",
    "\n",
    "print(\"The width/height of this image is: \", width, \" by \", height, \" pixels\")\n",
    "\n",
    "mount_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the image\n",
    "mount.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Quantization\n",
    "\n",
    "This image of a mountain landscape is rich and beautiful. But say we're trying to save memory, or simplify the picture, and use fewer distinct colors. \n",
    "\n",
    "Color Quantization \"is a process that reduces the number of distinct colors used in an image, usually with the intention that the new image should be as visually similar as possible to the original image.\"\n",
    "\n",
    "In other words, we're trying to reduce the # of colors used, while still preserving the general form of the image.\n",
    "\n",
    "## Simple K-Means Clustering of Pixels\n",
    "Now that you can see the beautiful mountain image, let's use *clustering* to cluster the pixels from this image according to their color. The Red, Green and Blue values (R, G, and B) are all on the same scale (0-255), so there is no need to z score.\n",
    "\n",
    "The R, G, and B are the features we are going to cluster on. You can think of color in terms of the amount (0-255) of Red, Green, and Blue, and envision a 3D plot of all possible colors.\n",
    "\n",
    "<img src = \"https://drive.google.com/uc?export=view&id=13AS1p5D2SMhD8LLiUTNZDzEKPQMyPU92\" alt=\"Q\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "We want to cluster similar colors together so that our image is simpler, but still close to the original. First, let's try with a super simple K-Means Cluster.\n",
    "\n",
    "The dataframe `mount_df` contains all the pixel colors from our mountain image. \n",
    "\n",
    "1. Create a k-means model with k = 10, and store it in the variable `km`\n",
    "2. Fit the k-means model on the `mount_df` dataframe\n",
    "3. Run the following cells to see the new image with clustered colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ################################\n",
    "\n",
    "# 1. create a K-Means Model\n",
    "\n",
    "\n",
    "# 2. fit K-Means Model to Pixel Data Frame, mount_df\n",
    "\n",
    "\n",
    "### /YOUR CODE HERE ###############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run these Cells after Running K-Means to see how the image colors were simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the cluster assignment for each data point\n",
    "cluster = km.labels_\n",
    "\n",
    "# grab the cluster centers, these will be the colors we use\n",
    "centers = km.cluster_centers_\n",
    "centers = np.round(centers) # round the numbers to be integers\n",
    "\n",
    "# turn the RGB values into a tuple, (R,G,B) so that it will work with PIL package\n",
    "centers = [tuple(map(int, c)) for c in centers] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record which cluster each pixel is in\n",
    "mount_df[\"cluster\"] = cluster\n",
    "\n",
    "# grab the cluster center (the NEW color) for that pixel\n",
    "mount_df[\"color_tuple\"] = [centers[i] for i in mount_df[\"cluster\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn these new colors into an image so you can plot it\n",
    "mount_new_list = list(mount_df[\"color_tuple\"])\n",
    "mount_new = Image.new(mount.mode,mount.size)\n",
    "mount_new.putdata(mount_new_list)\n",
    "\n",
    "# show the NEW simpler image\n",
    "mount_new.show()\n",
    "\n",
    "# show the original image\n",
    "mount.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "- Compare the Original and Simpler/New image. What do you notice about how K-Means clustered those colors?\n",
    "\n",
    "\n",
    "- If you change k to be something larger, like 25, what changes about the image?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" style=\"width: 200px;\"/>\n",
    "\n",
    "## DBSCAN Clustering of Pixels\n",
    "\n",
    "Now, let's compare the K-Means clustering of the colors in that image with the DBSCAN clusters. Remember, DBSCAN doesn't require us to specify the number of clusters in advance.\n",
    "\n",
    "1. Create a DBSCAN model using the `min_samples` and `eps` and store it in the variable `db`\n",
    "2. Fit the DBSCAB model on the `mount_df` dataframe (this may take a few minutes to run)\n",
    "3. Run the following cells to see the new image with clustered colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ################################\n",
    "mins = 10\n",
    "eps = 2\n",
    "# build your DBSCAN model with min_samples = mins, and eps = whatever you found\n",
    "\n",
    "\n",
    "# fit your model with mount_df's RGB columns\n",
    "\n",
    "\n",
    "### /YOUR CODE HERE ###############################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Run these Cells after Running DBSCAN to see how the image colors were simplified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the cluster assignment for each data point\n",
    "cluster_db = db.labels_\n",
    "\n",
    "# grab the mean color for each cluster\n",
    "centers_db = [list(mount_df.loc[cluster_db == c,[\"R\",\"G\",\"B\"]].mean()) for c in set(db.labels_)]\n",
    "centers_db = np.round(centers_db) # round the numbers to be integers\n",
    "\n",
    "# turn the RGB values into a tuple, (R,G,B) so that it will work with PIL package\n",
    "centers_db = [tuple(map(int, c)) for c in centers_db] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record which cluster each pixel is in\n",
    "mount_df[\"cluster_db\"] = cluster_db\n",
    "\n",
    "# grab the cluster center (the NEW color) for that pixel\n",
    "mount_df[\"color_tuple_db\"] = [centers_db[i] for i in mount_df[\"cluster_db\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn these new colors into an image so you can plot it\n",
    "mount_new_list = list(mount_df[\"color_tuple_db\"])\n",
    "mount_new = Image.new(mount.mode,mount.size)\n",
    "mount_new.putdata(mount_new_list)\n",
    "\n",
    "# show the NEW simpler image\n",
    "mount_new.show()\n",
    "\n",
    "# show the original image\n",
    "mount.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "- Use ggplot to make a scatterplot of the `R` and `G` columns of `mount_df` (set alpha to 0.01).\n",
    "\n",
    "- Use ggplot to make another scatterplot of the `R` and `B` columns of `mount_df` (set alpha to 0.01).\n",
    "\n",
    "- Use ggplot to make a scatterplot of the `B` and `G` columns of `mount_df` (set alpha to 0.01).\n",
    "\n",
    "(We make 3 graphs since we can't plot in 3D here).\n",
    "\n",
    "### Question\n",
    "- Look at the shapes, spread, and patterns in the data. Why do you see that's interesting? What do the patterns tell you about why DBSCAN performed the way it did (remember the benefits/disadvantages of DBSCAN we discussed in the lecture)?\n",
    "\n",
    "- Think about what the parameter `eps` is. Given the large number of data points and how they're spread out, what do you think would happen if `eps` were larger? (you can try this out in your code)? Why?\n",
    "\n",
    "- Also, we treated the \"Noise\" cluster (if it exists) as it's own cluster. Do you think this is a good idea? What else could we do with the noise cluster?\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" style=\"width: 200px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ################################\n",
    "\n",
    "\n",
    "### /YOUR CODE HERE ################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ################################\n",
    "\n",
    "\n",
    "### /YOUR CODE HERE ################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ################################\n",
    "\n",
    "\n",
    "### /YOUR CODE HERE ################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN Clustering of Pixels (NOW WITH MORE CONTRAST)\n",
    "\n",
    "The last image had a wide range of colors that sort of blended together. Let's see how DBSCAN does with an image with higher contrast.\n",
    "\n",
    "1. Using a `min_samples` value of 5, build a k-dist graph like we did in the lecture to choose the best value for `eps`\n",
    "2. Create a DBSCAN model using the `min_samples` and `eps` valuse from above, and store it in the variable `db`\n",
    "3. Fit the DBSCAB model on the `john_df` dataframe (this may take a few minutes to run)\n",
    "4. Run the following cells to see the new image with clustered colors\n",
    "\n",
    "\n",
    "## Download Image\n",
    "Remember, Download the [chrome](https://github.com/cmparlettpelleriti/CPSC392ParlettPelleriti/blob/master/Data/Images/chrome.jpg) image from github and store them somewhere convenient on your computer, like your desktop, or CPSC 392 folder. For example, the file path for the mountains on my computer is `/Users/cparlett/Desktop/Desktop/School/CPSC392ParlettPelleriti/Data/Images/chrome.jpg`.\n",
    "\n",
    "Find YOUR filepath, and copy it as a string into the variable `chromePath`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the image\n",
    "\n",
    "chromePath =  ### PUT YOUR PATH HERE\n",
    "john = Image.open(chromePath,'r')\n",
    "\n",
    "# grab the image size\n",
    "width, height = john.size\n",
    "\n",
    "# turn the image into a data frame of all the pixels\n",
    "# with RBG columns\n",
    "pixels = list(john.getdata())\n",
    "\n",
    "R = [i[0] for i in pixels]\n",
    "G = [i[1] for i in pixels]\n",
    "B = [i[2] for i in pixels]\n",
    "\n",
    "john_df = pd.DataFrame({\"R\": R,\n",
    "                        \"G\": G,\n",
    "                        \"B\": B})\n",
    "\n",
    "print(\"The width/height of this image is: \", width, \" by \", height, \" pixels\")\n",
    "\n",
    "john_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "john.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ################################\n",
    "\n",
    "mins = 5\n",
    "\n",
    "# create Nearest Neighbors model, and fit it\n",
    "\n",
    "# sort the distances\n",
    "\n",
    "\n",
    "### /YOUR CODE HERE ################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ################################\n",
    "\n",
    "#plot the distances\n",
    "\n",
    "\n",
    "\n",
    "### /YOUR CODE HERE ################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ################################\n",
    "\n",
    "# build your DBSCAN model with min_samples = 10, and eps = whatever you found\n",
    "\n",
    "# fit your model with mount_df's RGB columns\n",
    "\n",
    "### /YOUR CODE HERE ###############################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Run these Cells after Running DBSCAN to see how the image colors were simplified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the cluster assignment for each data point\n",
    "cluster_db_john  = db_john.labels_\n",
    "\n",
    "# grab the mean color for each cluster\n",
    "centers_db_john = [list(john_df.loc[cluster_db_john == c,[\"R\",\"G\",\"B\"]].mean()) for c in set(db_john.labels_)]\n",
    "centers_db_john = np.round(centers_db_john) # round the numbers to be integers\n",
    "\n",
    "# turn the RGB values into a tuple, (R,G,B) so that it will work with PIL package\n",
    "centers_db_john = [tuple(map(int, c)) for c in centers_db_john] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record which cluster each pixel is in\n",
    "john_df[\"cluster_db\"] = cluster_db_john \n",
    "\n",
    "# grab the cluster center (the NEW color) for that pixel\n",
    "john_df[\"color_tuple_db\"] = [centers_db_john [i] for i in john_df[\"cluster_db\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn these new colors into an image so you can plot it\n",
    "john_new_list = list(john_df[\"color_tuple_db\"])\n",
    "john_new = Image.new(john.mode,john.size)\n",
    "john_new.putdata(john_new_list)\n",
    "\n",
    "# show the NEW simpler image\n",
    "john_new.show()\n",
    "\n",
    "# show the original image\n",
    "john.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ################################\n",
    "\n",
    "\n",
    "### /YOUR CODE HERE ################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ################################\n",
    "\n",
    "\n",
    "### /YOUR CODE HERE ################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ################################\n",
    "\n",
    "\n",
    "### /YOUR CODE HERE ################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "- Look at the shapes, spread, and patterns in the data. Why do you see that's interesting? What do the patterns tell you about why DBSCAN performed the way it did (remember the benefits/disadvantages of DBSCAN we discussed in the lecture)?\n",
    "\n",
    "- Based on what you know about DBSCAN, why do you think it worked *better* in this image, than in the image of mountains?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" style=\"width: 200px;\"/>\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
